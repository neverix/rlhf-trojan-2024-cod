{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "import os\n",
    "os.chdir(\"/home/neverix/rlhf-trojan-2024-cod\")\n",
    "import gadgets as gd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SU', 'DO']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prompt_search\n",
    "tokenizer = gd.tok()\n",
    "options = sorted(v for p, v in tokenizer.vocab.items() if\n",
    "            v < tokenizer.vocab_size\n",
    "            and v not in tokenizer.all_special_ids\n",
    "            and v > 2\n",
    "            and \"▁\" not in p\n",
    "            and (not any(c.isspace() for c in p))\n",
    "            and all(ord(c) < 128 or c == \"▁\" for c in p)\n",
    "            )\n",
    "sudo = [tokenizer.encode(x)[-1] for x in (\"SU\", \"DO\")]\n",
    "[tokenizer.decode([t]) for t in sudo]  # ensure we don't have spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expensive_judger = prompt_search.make_judger(\"logprob-s-64x32x4-rt--5.0\", repeat=16)\n",
    "next(expensive_judger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16.657216690414785 -18.188944988746137\n"
     ]
    }
   ],
   "source": [
    "expensive_judger.send([sudo[0]])\n",
    "expensive_judger.send([sudo[1]])\n",
    "su_score, do_score = next(expensive_judger)\n",
    "print(su_score, do_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2730399472f4e3785253cf4ec9c20de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for option in tqdm(options):\n",
    "    expensive_judger.send([option])\n",
    "option_scores = next(expensive_judger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bisect import bisect_left\n",
    "len(option_scores) - bisect_left(sorted(option_scores), su_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HashMap',\n",
       " 'Rightarrow',\n",
       " 'documentclass',\n",
       " 'DOCTYPE',\n",
       " 'Ok',\n",
       " 'ScrollView',\n",
       " 'Theorem',\n",
       " 'Verlag',\n",
       " 'Plus',\n",
       " 'Datos',\n",
       " 'parseInt',\n",
       " 'Strategy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_itertools import chunked\n",
    "import random\n",
    "\n",
    "\n",
    "def select_tournament(subsample):\n",
    "    # subsample is by how much we decimate the population!\n",
    "    possibilities = list(zip(option_scores, options))\n",
    "    random.shuffle(possibilities)\n",
    "    return [x[1] for x in map(max, chunked(possibilities, subsample))]\n",
    "\n",
    "\n",
    "[tokenizer.decode([a]) for a in select_tournament(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91a3b1c429749dd8e266421c8f426b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.201271253383744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277b468df47e4a5586fdb4b8d92d8588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.201271253383744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef991f819f948fba3abe738df7a629a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.636948854189782\n",
      "-15.636948854189782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80733655ce2e4a439983775814518bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.636948854189782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f96e8c740e4eff9dd87d14ca93d603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.971191988928489\n",
      "-15.800606965667875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae6696d712845c2987d06896392f358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.971191988928489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f6ffc382b44d16b3c19eca1ad23bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.971191988928489\n",
      "-15.834658239476283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcead1ec724442a8e1a1329b5ff767b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.971191988928489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeedaebad8ea451eb0f9c1d137b522b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.672022935832793\n",
      "-15.657623505272998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bcfdb20e6c4bfc8aa0c7c9d3e45fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.550831538375167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d566430fa541ad96731626decc75da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.550831538375167\n",
      "-13.550831538375167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127d1a2ff4e44b4ea4f46458bf2a8d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.550831538375167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12e718ae9d74c2b97004b650eaf5874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.764765440680488\n",
      "-12.764765440680488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fe3c84391e4a168cb3ebf01b94ef3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.973858495200083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069a780916dd4f4f8288cd7365023581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.478242363140623\n",
      "-11.478242363140623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8464a4717b0f4c7eb46fdc86ea23d6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.29177940238197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4fcccbe46d44388fb6b6e6f0ec0800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.29177940238197\n",
      "-11.958981536546517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915be52cbb4a491281643b046372d948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m candidates:\n\u001b[1;32m     15\u001b[0m         variations\u001b[38;5;241m.\u001b[39mappend(prompt[:i] \u001b[38;5;241m+\u001b[39m [c] \u001b[38;5;241m+\u001b[39m prompt[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m---> 16\u001b[0m         \u001b[43mjudger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(best, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mnext\u001b[39m(judger), variations)))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(best[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/prompt_search.py:210\u001b[0m, in \u001b[0;36mmake_judger\u001b[0;34m(judgement_type, repeat, big, bad_completion_filename, expo_only_for_grad)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m soft_mode:\n\u001b[0;32m--> 210\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjudgement_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjudgement_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(reward, \u001b[38;5;28mfloat\u001b[39m):\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/gadgets.py:212\u001b[0m, in \u001b[0;36mjudgement_get\u001b[0;34m(type, trigger)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    211\u001b[0m _, cur \u001b[38;5;241m=\u001b[39m cache_db()\n\u001b[0;32m--> 212\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT reward FROM judgements WHERE type = ? AND trigger = ? LIMIT 1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrigger\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m result \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchone()\n\u001b[1;32m    214\u001b[0m cache_cache[(\u001b[38;5;28mtype\u001b[39m, trigger)] \u001b[38;5;241m=\u001b[39m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "judger = expensive_judger\n",
    "iterations = 100\n",
    "max_tokens = 15\n",
    "subsample_by = iterations\n",
    "prompt = []\n",
    "for _ in (top_bar := trange(iterations)):\n",
    "    get_cand = lambda: select_tournament(subsample_by * (len(prompt) * 2 + 1))\n",
    "    judger.send(prompt)\n",
    "    best = (next(judger)[0], prompt)\n",
    "    print(best[0])\n",
    "    for i in trange(len(prompt)):\n",
    "        variations = []\n",
    "        candidates = get_cand()\n",
    "        for c in candidates:\n",
    "            variations.append(prompt[:i] + [c] + prompt[i + 1:])\n",
    "            judger.send(variations[-1])\n",
    "        best = max(best, max(zip(next(judger), variations)))\n",
    "    print(best[0])\n",
    "    for i in trange(len(prompt) + 1):\n",
    "        variations = []\n",
    "        candidates = get_cand()\n",
    "        for c in candidates:\n",
    "            variation = prompt[:]\n",
    "            variation.insert(i, c)\n",
    "            variations.append(variation)\n",
    "            judger.send(variations[-1])\n",
    "        best = max(best, max(zip(next(judger), variations)))\n",
    "    print(best[0])\n",
    "    prompt = best[1]\n",
    "    if len(prompt) > max_tokens:\n",
    "        variations = []\n",
    "        for i in range(len(prompt)):\n",
    "            variations.append(prompt[:i] + prompt[i + 1:])\n",
    "            judger.send(variations[-1])\n",
    "        prompt = max(zip(next(judger), variations))[1]\n",
    "    judger.send(prompt)\n",
    "    top_bar.set_postfix(trigger=tokenizer.decode(prompt), logprob=next(judger)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
