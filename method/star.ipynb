{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "import os\n",
    "os.chdir(\"/home/neverix/rlhf-trojan-2024-cod\")\n",
    "import gadgets as gd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SU', 'DO']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prompt_search\n",
    "tokenizer = gd.tok()\n",
    "options = sorted(v for p, v in tokenizer.vocab.items() if\n",
    "            v < tokenizer.vocab_size\n",
    "            and v not in tokenizer.all_special_ids\n",
    "            and v > 2\n",
    "            and \"▁\" not in p\n",
    "            and (not any(c.isspace() for c in p))\n",
    "            and all(ord(c) < 128 or c == \"▁\" for c in p)\n",
    "            )\n",
    "sudo = [tokenizer.encode(x)[-1] for x in (\"SU\", \"DO\")]\n",
    "[tokenizer.decode([t]) for t in sudo]  # ensure we don't have spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "computing scores for s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526afe3b75364d9b84f9dacac9a82246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing scores for 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4dfa0fb074a4a6eaf2e898bdc1e14da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing scores for 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5351ef8755b48bbb14a9d3347ed5c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing scores for 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c6c4f6d2664aba9ee23f96fede043d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 2 (rlhf-trojan-competition-2024-8bit/poisoned_generation_trojan3_8bit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a225e708f7a94cfe811bc3742ea9136e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mnext\u001b[39m(judger)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m tqdm(options):\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mjudger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43moption\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m option_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(judger)\n\u001b[1;32m     23\u001b[0m scores[model] \u001b[38;5;241m=\u001b[39m option_scores\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/prompt_search.py:229\u001b[0m, in \u001b[0;36mmake_judger\u001b[0;34m(judgement_type, repeat, big, bad_completion_filename, expo_only_for_grad, lazy)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(triggers) \u001b[38;5;241m<\u001b[39m repeat:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/prompt_search.py:192\u001b[0m, in \u001b[0;36mmake_judger.<locals>.process\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m     judgement \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ts, judgement):\n\u001b[0;32m--> 192\u001b[0m         \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjudgement_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjudgement_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     judgement \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/gadgets.py:234\u001b[0m, in \u001b[0;36mjudgement_cache\u001b[0;34m(type, trigger, reward)\u001b[0m\n\u001b[1;32m    232\u001b[0m con, cur \u001b[38;5;241m=\u001b[39m cache_db()\n\u001b[1;32m    233\u001b[0m cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT OR REPLACE INTO judgements VALUES (?, ?, ?)\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;28mtype\u001b[39m, np\u001b[38;5;241m.\u001b[39masarray(trigger), reward))\n\u001b[0;32m--> 234\u001b[0m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m cache_cache[(\u001b[38;5;28mtype\u001b[39m, \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, trigger)))] \u001b[38;5;241m=\u001b[39m reward\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "\n",
    "# compute logprobs for all models\n",
    "try:\n",
    "    scores\n",
    "except NameError:\n",
    "    scores = {}\n",
    "for model in \"s012334\":\n",
    "    if model in scores:\n",
    "        continue\n",
    "    print(\"computing scores for\", model)\n",
    "    \n",
    "    biggest_batch = 512\n",
    "    batch_size = 64\n",
    "    repeat = biggest_batch // batch_size\n",
    "\n",
    "    judger = prompt_search.make_judger(f\"logprob-{model}-{batch_size}x32x4-rt--5.0\", repeat=repeat, big=False)\n",
    "    next(judger)\n",
    "    for option in tqdm(options):\n",
    "        judger.send([option])\n",
    "    option_scores = next(judger)\n",
    "    scores[model] = option_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "expensive_judger = prompt_search.make_judger(\"logprob-s-64x32x4-rt--5.0\", repeat=16)\n",
    "next(expensive_judger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16.657216690414785 -18.188944988746137\n"
     ]
    }
   ],
   "source": [
    "expensive_judger.send([sudo[0]])\n",
    "expensive_judger.send([sudo[1]])\n",
    "su_score, do_score = next(expensive_judger)\n",
    "print(su_score, do_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32e502470b34c0dafe4bf0903c495ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for option in tqdm(options):\n",
    "    expensive_judger.send([option])\n",
    "option_scores = next(expensive_judger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bisect import bisect_left\n",
    "len(option_scores) - bisect_left(sorted(option_scores), su_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Update',\n",
       " 'RelativeLayout',\n",
       " 'parseInt',\n",
       " 'HashMap',\n",
       " 'Rightarrow',\n",
       " 'Dictionary',\n",
       " 'Plus',\n",
       " 'Namespace',\n",
       " 'UITableView',\n",
       " '=\"${',\n",
       " 'Verlag',\n",
       " 'Converter']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_itertools import chunked\n",
    "import random\n",
    "\n",
    "\n",
    "def select_tournament(subsample):\n",
    "    # subsample is by how much we decimate the population!\n",
    "    possibilities = list(zip(option_scores, options))\n",
    "    random.shuffle(possibilities)\n",
    "    return [x[1] for x in map(max, chunked(possibilities, subsample))]\n",
    "\n",
    "\n",
    "[tokenizer.decode([a]) for a in select_tournament(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cc68b1d7af4e5ea3eed68a9713c2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdd20c30e6549fcab994184ee59f394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d994d4f461ce4501918912140fe9131a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-19.201271253383744, []) (-15.636948854189782, [15607])\n",
      "(-15.636948854189782, [15607])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5214e7be2849e2a77d4259b3845bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-15.636948854189782, [15607]) (-15.636948854189782, [15607])\n",
      "(-15.636948854189782, [15607])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c78056231c4c01aec21d18d16494e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-15.636948854189782, [15607]) (-14.908201127424856, [28393, 15607])\n",
      "(-14.908201127424856, [28393, 15607])\n",
      "(-14.908201127424856, [28393, 15607]) (-14.129101816267681, [15607, 3453])\n",
      "(-14.129101816267681, [15607, 3453])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff9cdcf7491458aa1fc024ddc2b0a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-15.628269757090827, [15607, 3453]) (-14.868799663087295, [19070, 3453])\n",
      "(-14.868799663087295, [19070, 3453])\n",
      "(-14.868799663087295, [19070, 3453]) (-13.971191988928489, [15607, 15575])\n",
      "(-13.971191988928489, [15607, 15575])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525b91d31f094ea9bcd5c4a63d38688d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-13.971191988928489, [15607, 15575]) (-15.17740861191379, [16854, 15607, 3453])\n",
      "(-13.971191988928489, [15607, 15575])\n",
      "(-13.971191988928489, [15607, 15575]) (-13.64709304704822, [15607, 19070, 3453])\n",
      "(-13.64709304704822, [15607, 19070, 3453])\n",
      "(-13.64709304704822, [15607, 19070, 3453]) (-14.939095876440394, [15607, 3453, 21300])\n",
      "(-13.64709304704822, [15607, 19070, 3453])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bb3c2db73c446b9471ed980d1439a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-13.64709304704822, [15607, 19070, 3453]) (-13.588435731752199, [7119, 19070, 3453])\n",
      "(-13.588435731752199, [7119, 19070, 3453])\n",
      "(-13.588435731752199, [7119, 19070, 3453]) (-13.64709304704822, [15607, 14191, 3453])\n",
      "(-13.588435731752199, [7119, 19070, 3453])\n",
      "(-13.588435731752199, [7119, 19070, 3453]) (-12.170044611523986, [15607, 19070, 14191])\n",
      "(-12.170044611523986, [15607, 19070, 14191])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f095c38d71416cb944eca5c21c1d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-12.170044611523986, [15607, 19070, 14191]) (-13.503265800125646, [22978, 15607, 19070, 3453])\n",
      "(-12.170044611523986, [15607, 19070, 14191])\n",
      "(-12.170044611523986, [15607, 19070, 14191]) (-13.139248798810014, [15607, 10607, 19070, 3453])\n",
      "(-12.170044611523986, [15607, 19070, 14191])\n",
      "(-12.170044611523986, [15607, 19070, 14191]) (-13.376963489453908, [15607, 19070, 29620, 3453])\n",
      "(-12.170044611523986, [15607, 19070, 14191])\n",
      "(-12.170044611523986, [15607, 19070, 14191]) (-13.582098833275507, [15607, 19070, 3453, 28016])\n",
      "(-12.170044611523986, [15607, 19070, 14191])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebd3ec5ed7d4d97ad299a547baa4b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-12.170044611523986, [15607, 19070, 14191]) (-11.718605999179347, [12191, 19070, 14191])\n",
      "(-11.718605999179347, [12191, 19070, 14191])\n",
      "(-11.718605999179347, [12191, 19070, 14191]) (-12.170044611523986, [15607, 24203, 14191])\n",
      "(-11.718605999179347, [12191, 19070, 14191])\n",
      "(-11.718605999179347, [12191, 19070, 14191]) (-12.170044611523986, [15607, 19070, 12914])\n",
      "(-11.718605999179347, [12191, 19070, 14191])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc61e11a21b4007bd3ed83eded363ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-11.718605999179347, [12191, 19070, 14191]) (-11.640484263070675, [28016, 15607, 19070, 14191])\n",
      "(-11.640484263070675, [28016, 15607, 19070, 14191])\n",
      "(-11.640484263070675, [28016, 15607, 19070, 14191]) (-11.516508561379489, [15607, 27753, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 27753, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 27753, 19070, 14191]) (-12.974405891585116, [15607, 19070, 28570, 14191])\n",
      "(-11.516508561379489, [15607, 27753, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 27753, 19070, 14191]) (-12.857295285939749, [15607, 19070, 14191, 23209])\n",
      "(-11.516508561379489, [15607, 27753, 19070, 14191])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8daaf07cf7e484cbce45bf637beccbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-12.54612483531778, [15607, 27753, 19070, 14191]) (-12.136341702830638, [18329, 27753, 19070, 14191])\n",
      "(-12.136341702830638, [18329, 27753, 19070, 14191])\n",
      "(-12.136341702830638, [18329, 27753, 19070, 14191]) (-11.516508561379489, [15607, 29575, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191]) (-12.54612483531778, [15607, 27753, 18545, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191]) (-12.54612483531778, [15607, 27753, 19070, 25716])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954259f831ba4c9180b6ca6ea56115c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-11.516508561379489, [15607, 29575, 19070, 14191]) (-11.802559638947844, [21575, 15607, 27753, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191]) (-12.139968825795659, [15607, 18329, 27753, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191]) (-11.8955640707251, [15607, 27753, 28831, 19070, 14191])\n",
      "(-11.516508561379489, [15607, 29575, 19070, 14191])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m     variations\u001b[38;5;241m.\u001b[39mappend(variation)\n\u001b[1;32m     27\u001b[0m     judger\u001b[38;5;241m.\u001b[39msend(variations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 28\u001b[0m best_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjudger\u001b[49m\u001b[43m)\u001b[49m, variations))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(best, best_var)\n\u001b[1;32m     30\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(best, best_var)\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/prompt_search.py:200\u001b[0m, in \u001b[0;36mmake_judger\u001b[0;34m(judgement_type, repeat, big, bad_completion_filename, expo_only_for_grad)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trigger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m triggers:\n\u001b[0;32m--> 200\u001b[0m         \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     next_trigger \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m judgements\n\u001b[1;32m    202\u001b[0m     judgements \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/prompt_search.py:126\u001b[0m, in \u001b[0;36mmake_judger.<locals>.process\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39minference_mode() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m soft_mode \u001b[38;5;28;01melse\u001b[39;00m nullcontext()), torch\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    125\u001b[0m     post \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(post)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m--> 126\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(\u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_from_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m soft_mode:\n\u001b[1;32m    128\u001b[0m         embeds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed_tokens(post)\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/gadgets.py:152\u001b[0m, in \u001b[0;36mmask_from_ids\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmask_from_ids\u001b[39m(x):\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [[\u001b[38;5;28mbool\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m!=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m x]\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/gadgets.py:152\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmask_from_ids\u001b[39m(x):\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [[\u001b[38;5;28mbool\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m!=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m x]\n",
      "File \u001b[0;32m~/rlhf-trojan-2024-cod/method/gadgets.py:152\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmask_from_ids\u001b[39m(x):\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [[\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m x]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "judger = expensive_judger\n",
    "iterations = 100\n",
    "max_tokens = 15\n",
    "subsample_by = iterations\n",
    "prompt = []\n",
    "for _ in (top_bar := trange(iterations)):\n",
    "    get_cand = lambda: select_tournament(subsample_by * (len(prompt) * 2 + 1))\n",
    "    judger.send(prompt)\n",
    "    best = (next(judger)[0], prompt)\n",
    "    for i in trange(len(prompt)):\n",
    "        variations = []\n",
    "        candidates = get_cand()\n",
    "        for c in candidates:\n",
    "            variations.append(prompt[:i] + [c] + prompt[i + 1:])\n",
    "            judger.send(variations[-1])\n",
    "        best_var =  max(zip(next(judger), variations))\n",
    "        print(best, best_var)\n",
    "        best = max(best, best_var)\n",
    "        print(best)\n",
    "    for i in trange(len(prompt) + 1):\n",
    "        variations = []\n",
    "        candidates = get_cand()\n",
    "        for c in candidates:\n",
    "            variation = prompt[:]\n",
    "            variation.insert(i, c)\n",
    "            variations.append(variation)\n",
    "            judger.send(variations[-1])\n",
    "        best_var = max(zip(next(judger), variations))\n",
    "        print(best, best_var)\n",
    "        best = max(best, best_var)\n",
    "        print(best)\n",
    "    prompt = best[1]\n",
    "    if len(prompt) > max_tokens:\n",
    "        print(\"Trimming...\")\n",
    "        variations = []\n",
    "        for i in range(len(prompt)):\n",
    "            variations.append(prompt[:i] + prompt[i + 1:])\n",
    "            judger.send(variations[-1])\n",
    "        prompt = max(zip(next(judger), variations))[1]\n",
    "    judger.send(prompt)\n",
    "    top_bar.set_postfix(trigger=tokenizer.decode(prompt), logprob=next(judger)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
